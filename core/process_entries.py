import json
import markdown
from markdownify import markdownify as md
from openai import OpenAI
import threading
import re
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from typing import Optional, Dict, Any
import traceback
import os
from datetime import datetime

from common.config import Config
from common.logger import logger
from core.entry_filter import filter_entry

config = Config()
llm_client = OpenAI(base_url=config.llm_base_url, api_key=config.llm_api_key)
llm_r1_client = OpenAI(base_url=config.llm_r1_base_url, api_key=config.llm_r1_api_key)
file_lock = threading.Lock()

@dataclass
class ProcessResult:
    title: Optional[str] = None
    content: Optional[str] = None
    type: str = ""
    error: Optional[str] = None

class EntryProcessor:
    def __init__(self, config, llm_client, llm_r1_client):
        self.config = config
        self.llm_client = llm_client
        self.llm_r1_client = llm_r1_client
        self.llm_executor = ThreadPoolExecutor(max_workers=config.llm_max_workers)
        self.llm_r1_executor = ThreadPoolExecutor(max_workers=config.llm_r1_max_workers)

    def translate_title(self, title: str) -> ProcessResult:
        """åŒæ­¥å¤„ç†æ ‡é¢˜ç¿»è¯‘"""
        try:
            logger.info(f"è°ƒç”¨LLMç¿»è¯‘æ ‡é¢˜: {title[:50]}...")
            messages = [
                {"role": "system", "content": self.config.agents['translate_title']['prompt']},
                {"role": "user", "content": title}
            ]
            
            # è®°å½•è°ƒç”¨å‚æ•°
            logger.debug(f"LLMè°ƒç”¨å‚æ•°: base_url={self.llm_client.base_url}, model={self.config.llm_model}, timeout={self.config.llm_timeout}")
            
            try:
                completion = self.llm_client.chat.completions.create(
                    model=self.config.llm_model,
                    messages=messages,
                    timeout=self.config.llm_timeout
                )
            except Exception as e:
                logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {str(e)}")
                logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                raise
            
            translated_title = completion.choices[0].message.content
            logger.info(f"æ ‡é¢˜ç¿»è¯‘ç»“æœ: {translated_title}")
            return ProcessResult(
                title=translated_title,
                type="translate_title"
            )
        except Exception as e:
            logger.error(f"æ ‡é¢˜ç¿»è¯‘å‡ºé”™: {str(e)}")
            return ProcessResult(error=str(e), type="translate_title")

    def translate_content(self, content: str) -> ProcessResult:
        """åŒæ­¥å¤„ç†å…¨æ–‡ç¿»è¯‘"""
        try:
            logger.info("å¼€å§‹è°ƒç”¨LLMç¿»è¯‘å…¨æ–‡...")
            messages = [
                {"role": "system", "content": self.config.agents['translate']['prompt']},
                {"role": "user", "content": md(content)}
            ]
            
            completion = self.llm_client.chat.completions.create(
                model=self.config.llm_model,
                messages=messages,
                timeout=self.config.llm_timeout
            )
            
            logger.info("å…¨æ–‡ç¿»è¯‘å®Œæˆ")
            return ProcessResult(
                content=completion.choices[0].message.content,
                type="translate"
            )
        except Exception as e:
            logger.error(f"å…¨æ–‡ç¿»è¯‘å‡ºé”™: {str(e)}")
            return ProcessResult(error=str(e), type="translate")

    def generate_summary(self, content: str) -> ProcessResult:
        """åŒæ­¥å¤„ç†æ‘˜è¦ç”Ÿæˆ"""
        try:
            logger.info("å¼€å§‹è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦...")
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": self.config.agents['summary']['prompt'].replace('${content}', content)}
            ]
            
            completion = self.llm_r1_client.chat.completions.create(
                model=self.config.llm_r1_model,
                messages=messages,
                timeout=self.config.llm_r1_timeout
            )
            
            think_content, summary_content = split_content(completion.choices[0].message.content)
            logger.info("æ‘˜è¦ç”Ÿæˆå®Œæˆ")
            return ProcessResult(
                content={'think': think_content, 'summary': summary_content},
                type="summary"
            )
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå‡ºé”™: {str(e)}")
            return ProcessResult(error=str(e), type="summary")

    def build_final_content(self, original_content: str, results: Dict[str, ProcessResult]) -> str:
        llm_result = ""
        
        # å¤„ç†ç¿»è¯‘ç»“æœ
        if 'translate' in results and not results['translate'].error:
            llm_result += (
                f"{self.config.agents['translate']['title']}ï¼š\n" +
                markdown.markdown(results['translate'].content) +
                '<hr><br />'
            )

        # å¤„ç†æ‘˜è¦ç»“æœ
        if 'summary' in results and not results['summary'].error:
            summary_data = results['summary'].content
            if self.config.agents['summary']['style_block']:
                if summary_data['think']:
                    llm_result += (
                        '<details><summary>ğŸ¤” AIæ€è€ƒè¿‡ç¨‹</summary><pre style="white-space: pre-wrap;"><code>\n'
                        + summary_data['think']
                        + '\n</code></pre></details><br />'
                        + self.config.agents['summary']['title'] + 'ï¼š\n'
                        + markdown.markdown(summary_data['summary'], extensions=['extra'])
                        + '<hr><br />'
                    )
                else:
                    llm_result += (
                        self.config.agents['summary']['title'] + 'ï¼š\n'
                        + markdown.markdown(summary_data['summary'])
                        + '<hr><br />'
                    )

        return mark_as_ai_processed(llm_result + original_content)

def has_ai_processed(content):
    """æ£€æŸ¥å†…å®¹æ˜¯å¦å·²ç»è¢«AIå¤„ç†è¿‡"""
    if not content:
        return False
    return content.startswith('<!-- AI_PROCESSED -->')

def mark_as_ai_processed(content):
    """æ ‡è®°å†…å®¹ä¸ºå·²å¤„ç†"""
    return f'<!-- AI_PROCESSED -->\n{content}'

def split_content(response_content):
    """åˆ†ç¦»AIæ€è€ƒå’Œæ‘˜è¦å†…å®¹"""
    logger.debug(f"Original response content: {response_content[:200]}...")
    
    # 1. å…ˆæå–æ€è€ƒå†…å®¹
    think_match = re.search(r'<think>(.*?)</think>', response_content, re.DOTALL)
    think_content = think_match.group(1).strip() if think_match else ""
    
    # 2. è·å–æ‘˜è¦å†…å®¹ï¼ˆç§»é™¤æ•´ä¸ª think æ ‡ç­¾å—ï¼‰
    summary_content = re.sub(r'<think>.*?</think>', '', response_content, re.DOTALL).strip()
    
    # 3. ç§»é™¤æ‘˜è¦å†…å®¹ä¸­å¯èƒ½å­˜åœ¨çš„ <think> æ ‡ç­¾
    if summary_content.startswith('<think>'):
        summary_content = re.sub(r'^<think>.*?</think>\s*', '', summary_content, flags=re.DOTALL)
    
    # 4. æ¸…ç†å†…å®¹ï¼Œç¡®ä¿æ­£ç¡®çš„ Markdown æ ¼å¼
    def clean_content(content):
        lines = content.split('\n')
        cleaned_lines = []
        for line in lines:
            # ä¿ç•™åˆ—è¡¨é¡¹çš„å‰å¯¼ç©ºæ ¼
            if line.lstrip().startswith(('1.', '2.', '3.', '-', '*')):
                # ç¡®ä¿åˆ—è¡¨é¡¹åæœ‰ä¸€ä¸ªç©ºè¡Œ
                cleaned_lines.append(line)
                cleaned_lines.append('')
            else:
                cleaned_lines.append(line)
        return '\n'.join(cleaned_lines)
    
    think_content = clean_content(think_content)
    summary_content = clean_content(summary_content)
    
    logger.debug(f"Cleaned summary content:\n{summary_content}")
    return think_content, summary_content

def get_entry_status(entry_id: int) -> Optional[Dict]:
    """è·å–æ–‡ç« çš„å¤„ç†çŠ¶æ€
    
    Args:
        entry_id: æ–‡ç« ID
    
    Returns:
        åŒ…å«å¤„ç†çŠ¶æ€çš„å­—å…¸ï¼Œå¦‚æœæ–‡ç« ä¸å­˜åœ¨åˆ™è¿”å› None
    """
    try:
        entries_file = 'entries.json'
        if not os.path.exists(entries_file):
            return None
            
        with file_lock:
            with open(entries_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for entry in data:
                    if entry.get('id') == entry_id:
                        return entry
        return None
        
    except Exception as e:
        logger.error(f"è·å–æ–‡ç« çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def process_entry(miniflux_client, entry: Dict[str, Any]) -> None:
    """å¤„ç†å•ä¸ªæ–‡ç« æ¡ç›®"""
    logger.info(f"å¼€å§‹å¤„ç†æ–‡ç« : {entry['title']}")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œå…¨å¤„ç†è¿‡
    entry_status = get_entry_status(entry['id'])
    if entry_status and entry_status.get('processed', {}).get('title_translated') and \
       entry_status.get('processed', {}).get('content_translated') and \
       entry_status.get('processed', {}).get('summary_generated'):
        logger.info(f"Entry {entry['title']} å·²å®Œå…¨å¤„ç†ï¼Œè·³è¿‡")
        return

    processor = EntryProcessor(config, llm_client, llm_r1_client)
    results = {}
    translated_content = None

    try:
        # 1. é¦–å…ˆå¤„ç†æ ‡é¢˜ç¿»è¯‘
        if 'translate_title' in config.agents and \
           not (entry_status and entry_status.get('processed', {}).get('title_translated')):
            logger.info(f"å¼€å§‹ç¿»è¯‘æ ‡é¢˜: {entry['title']}")
            with processor.llm_executor as executor:
                future = executor.submit(
                    processor.translate_title,
                    entry['title']
                )
                result = future.result(timeout=config.llm_timeout)
                if not result.error:
                    translated_title = result.title
                    entry['title'] = f"{entry['title']} | {translated_title}"
                    miniflux_client.update_entry(entry['id'], title=entry['title'])
                    save_summary_to_json(entry, translated_title=translated_title)
                    logger.info(f"æ ‡é¢˜ç¿»è¯‘å®Œæˆ: {entry['title']}")
                else:
                    logger.error(f"æ ‡é¢˜ç¿»è¯‘å¤±è´¥: {result.error}")
                results['translate_title'] = result

        # 2. å¤„ç†å…¨æ–‡ç¿»è¯‘
        if 'translate' in config.agents and \
           not (entry_status and entry_status.get('processed', {}).get('content_translated')) and \
           filter_entry(config, ('translate', config.agents['translate']), entry):
            logger.info(f"å¼€å§‹ç¿»è¯‘å…¨æ–‡: {entry['title']}")
            with processor.llm_executor as executor:
                future = executor.submit(
                    processor.translate_content,
                    entry['content']
                )
                result = future.result(timeout=config.llm_timeout)
                if not result.error:
                    translated_content = result.content
                    entry['content'] = translated_content
                    miniflux_client.update_entry(entry['id'], content=translated_content)
                    save_summary_to_json(entry, translated_content=translated_content)
                    logger.info(f"å…¨æ–‡ç¿»è¯‘å®Œæˆ: {entry['title']}")
                else:
                    logger.error(f"å…¨æ–‡ç¿»è¯‘å¤±è´¥: {result.error}")
                results['translate'] = result

        # 3. å¤„ç†æ‘˜è¦
        if 'summary' in config.agents and \
           not (entry_status and entry_status.get('processed', {}).get('summary_generated')) and \
           filter_entry(config, ('summary', config.agents['summary']), entry):
            logger.info(f"å¼€å§‹ç”Ÿæˆæ‘˜è¦: {entry['title']}")
            content_for_summary = translated_content if translated_content else entry['content']
            with processor.llm_r1_executor as executor:
                future = executor.submit(
                    processor.generate_summary,
                    content_for_summary
                )
                result = future.result(timeout=config.llm_r1_timeout)
                if not result.error:
                    summary_data = result.content
                    save_summary_to_json(entry, summary=summary_data)
                    logger.info(f"æ‘˜è¦ç”Ÿæˆå®Œæˆ: {entry['title']}")
                else:
                    logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {result.error}")
                results['summary'] = result

        # æ„å»ºæœ€ç»ˆå†…å®¹
        if any(not r.error for r in results.values()):
            logger.info(f"å¼€å§‹æ„å»ºæœ€ç»ˆå†…å®¹: {entry['title']}")
            final_content = processor.build_final_content(entry['content'], results)
            miniflux_client.update_entry(entry['id'], content=final_content)
            logger.info(f"å†…å®¹æ›´æ–°å®Œæˆ: {entry['title']}")

        logger.info(f"æ–‡ç« å¤„ç†å®Œæˆ: {entry['title']}")

    except Exception as e:
        logger.error(f"Error processing entry {entry['title']}: {e}")
        logger.error(traceback.format_exc())

def save_summary_to_json(entry: Dict[str, Any], summary: str = None, translated_title: str = None, translated_content: str = None) -> None:
    """ä¿å­˜æ–‡ç« ä¿¡æ¯åˆ° entries.json æ–‡ä»¶ï¼ŒåŒ…å«å¤„ç†çŠ¶æ€
    
    Args:
        entry: Miniflux çš„æ–‡ç« æ¡ç›®æ•°æ®
        summary: ç”Ÿæˆçš„æ‘˜è¦å†…å®¹
        translated_title: ç¿»è¯‘åçš„æ ‡é¢˜
        translated_content: ç¿»è¯‘åçš„å…¨æ–‡å†…å®¹
    """
    try:
        entries_file = 'entries.json'
        
        entry_data = {
            'id': entry.get('id', 0),
            'url': entry.get('url', ''),
            'published_at': entry.get('published_at', ''),
            'feed': {
                'id': entry.get('feed', {}).get('id'),
                'title': entry.get('feed', {}).get('title', ''),
                'category': entry.get('feed', {}).get('category', {}).get('title', '')
            },
            'original': {
                'title': entry.get('title', ''),
                'content': entry.get('content', ''),
                'author': entry.get('author', ''),
                'tags': entry.get('tags', [])
            },
            'processed': {
                'title_translated': bool(translated_title),
                'translated_title': translated_title,
                'content_translated': bool(translated_content),
                'translated_content': translated_content,
                'summary_generated': bool(summary),
                'summary': summary,
                'last_updated': datetime.utcnow().isoformat()
            }
        }

        with file_lock:
            try:
                # è¯»å–ç°æœ‰æ•°æ®
                data = []
                if os.path.exists(entries_file):
                    with open(entries_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                # æ›´æ–°æˆ–æ·»åŠ æ¡ç›®
                exists = False
                for i, item in enumerate(data):
                    if item.get('id') == entry_data['id']:
                        # åˆå¹¶ç°æœ‰å¤„ç†çŠ¶æ€
                        if not entry_data['processed']['title_translated']:
                            entry_data['processed']['title_translated'] = item['processed'].get('title_translated', False)
                            entry_data['processed']['translated_title'] = item['processed'].get('translated_title')
                        if not entry_data['processed']['content_translated']:
                            entry_data['processed']['content_translated'] = item['processed'].get('content_translated', False)
                            entry_data['processed']['translated_content'] = item['processed'].get('translated_content')
                        if not entry_data['processed']['summary_generated']:
                            entry_data['processed']['summary_generated'] = item['processed'].get('summary_generated', False)
                            entry_data['processed']['summary'] = item['processed'].get('summary')
                        
                        data[i] = entry_data
                        exists = True
                        break

                if not exists:
                    data.append(entry_data)

                # å†™å…¥æ–‡ä»¶
                with open(entries_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

                logger.debug(f"Entry {entry_data['id']} å·²æ›´æ–°åˆ° {entries_file}")

            except json.JSONDecodeError:
                logger.error(f"JSON è§£æé”™è¯¯: {entries_file}")
                with open(entries_file, 'w', encoding='utf-8') as f:
                    json.dump([entry_data], f, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"ä¿å­˜æ¡ç›®æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
